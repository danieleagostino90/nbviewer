


Murray and Bryan, 


































Let me first thank you for allowing me to participate in this project. Studying and analyzing data always gets my juices flowing. Also, being able to interact with you two has been a joy. 

Let me walk you through what I have done, as I have kept the summary, conclusions and recommendations in this top part of the page. The code is at the bottom for your review and reference. 


































This analysis is composed of two parts: 
•regression analysis (Random Forest) to capture key features 
•robustness test via study of relative variance
































As far as the regression analysis, I conducted a Monte Carlo on the different parameters of the regression analysis (basically, the Random Forest method gives flexibility of choice on the end-user as far as randomness is concerned). As a result, the top features that have had the most prediction power towards Leadership Effectiveness are:









































Feature

Avg. Predictory Power

StDev/Mean %


Integrity (others) 58% 7.8% 
Vision (others) 21.5% 21.9% 
Teamwork (others) 3.35% 46.0% 
Strategy (others) 3.0 % 48.2% 
Decisions (others) 2.88% 57.5% 
Composure (self) 2.2% 148.5% 







































I personally like to study the StDev/Mean %, as a measure of how much dispersion there is in the results relative to the mean. As a personal rule of thumbs, anything less that 50% is great (to give you a practical example, Large Cap stocks tend to have a 10% return with a 12% stdev. That's a 120% StDev/Mean ratio. The lowest the better).

Integrity perceived from others is the most meaningful and least disperse indicator, by a long shot. Vision perceived from others is the second most relevant feature. 

Anything after that is not statistically significant for the overall Leadership Effectiveness. I only want to bring your attention that the first self-perceived feature to have any relevance is Composure. 

If you want to create your own model, I would highly recommend getting deeper into the Integrity and Vision features, as perceived by others. Everything else can be carefully ignored. 




































As asked, here is my robustness analysis. The second part of my deliverables.

I hope we can agree that robustness can be safely analyzed by the disperion of data point. The more dispersion around its mean, the bigger the chance for presence of outliers, and the least confidence on any inference on the dataset. 

On this assumption, let me report what were the features with the biggest dispersion around its mean, along with the relative disperion, as before. 








































Feature

Avg. Dispersion

StDev/Mean %


Arrogance (others) 31.1% 67.1% 
Decisions (self) 30.5% 60.9% 
Passive (others) 30.3% 76.3% 
Composure (others) 30.2% 52.5% 
Decisions (others) 30.1% 58.7% 
Pleasing (self) 29.0% 73.0% 


































Overall, the relative dispersion to the mean stay below 50%, which I like. 

The only feature that had a significant predicting power along with a relatively high dispersion is Decisions as perceived by others. 






































In conclusion, if I were to build a model, I would focus exclusively on the Integrity and Vision features of a leader as perceived by others. Specialize in these two features, and I believe you can have an edge. With the current data, I don't see any valid reason to focus on other features. At least, not substantially. 

As far as the robustness of the data, I see a very nice consistency among dispersion of data between different features. I don't see any red flag, no outlier or specific indicator that there is any bias in our conclusions. 

I am confident that the more data points we collect, the more the stability of the model will be enhanced, and confirmed. 

Now, to the next project!




In [ ]:



























​











In [1]:



























#IMPORTS
from tabula import read_pdf
import pandas as pd
import os
import numpy as np
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import statistics











In [ ]:



























​











In [2]:



























#SET UP 
​
#set up directory path
directory = "C:\\Users\\Owner\\Desktop\\Coach Report\\" 
​
#set up columns and index labels
df = read_pdf("C:\\Users\\Owner\\Desktop\\Coach Report\\Aggregate.pdf")
index = df['Unnamed: 0'].values[2:]
columns = list(range(0, len(os.listdir(directory))))
​
#initialize tables 
table_self = pd.DataFrame(index= index, columns= range(len(os.listdir(directory))) )
table_othe = pd.DataFrame(index= index, columns= range(len(os.listdir(directory))) )











In [ ]:



























​











In [3]:



























#CREATE DATASET
#RETRIEVE AND CLEAN UP DATA
​
#initiate col index
col_index=0
​
#loop through the pdf files in the directory
for report in os.listdir(directory):
    
    #for each file, extract table
    app = read_pdf(directory + str(report))
    
    #remove nan values 
    app = app[:][-len([x for x in app[app.columns.values[0]].values if str(x) != 'nan']):]
    
    #replace '-' with 0's
    for i in app.index.values:
        for j in app.columns.values:
            if (app[str(j)][i]== '-'):
                app[str(j)][i]='0 %'
    
    #change from string values to float percentages
    for i in range(0, len(app[app.columns.values[1]].values)):
        app[app.columns.values[1]].values[i] = float(app[app.columns.values[1]].values[i][:-1])/100
        app[app.columns.values[2]].values[i] = float(app[app.columns.values[2]].values[i][:-1])/100
    
    #turn into dataframe to populate later the tables
    app = pd.DataFrame( app[app.columns.values[1:3]].values, index = index, columns = app.columns[1:3].values )
    
    #populate tables with current report percentages
    for i in app.index.values:
        table_self[col_index][i]= app[str(app.columns.values[0])][i]
        table_othe[col_index][i]= app[str(app.columns.values[1])][i]
    
    #update col index
    col_index=col_index+1    
    
#drop last three rows because not important  
table_self = table_self.drop(index[-4:-1])
table_othe = table_othe.drop(index[-4:-1])
​
#merge tables into one
table = table_self.T.join(table_othe.T, lsuffix='_self', rsuffix='_othe')
​
#REMOVE CATEGORIES
table = table.drop(['Relating_self', 'Being_self', 'Achieving_self', 
                    'Controlling_self', 'Protecting_self', 
                    'Complying_self', 'Relating_othe', 'Being_othe',
                    'Achieving_othe', 'Controlling_othe', 
                    'Protecting_othe', 'Complying_othe'], axis=1)











In [ ]:



























​











In [11]:



























#Feature Selection using Random Forest Regressor (EXAMPLE)
X_train, X_test, y_train, y_test = train_test_split(table.iloc[:, :-1],table.iloc[:,-1] , test_size=0.10)
model = RandomForestRegressor(n_estimators = 100)
model.fit(X_train,y_train)
​
features = table.columns
importances = model.feature_importances_
indices = np.argsort(importances)[-16:]  # top x features
#plt.title('Feature Importances')
#plt.barh(range(len(indices)), importances[indices], color='b', align='center')
#plt.yticks(range(len(indices)), [features[i] for i in indices])
#plt.xlabel('Relative Importance')
​
#plt.show()











In [ ]:



























​











In [15]:



























#MONTE CARLO ON RANDOM FOREST PARAMETERS FOR FEATURES IMPORTANCE
table_f = pd.DataFrame(index = table.columns , columns = [list(range(100))+list(['Mean', 'Stdev', 'Stdev/Mean %'])])
for i in range(100):
    if (i>0):
        model = RandomForestRegressor(n_estimators = i)
        model.fit(X_train,y_train)
        features = table.columns
        importances = model.feature_importances_
        indices = np.argsort(importances)[-10:]  # top 10 features
        for j in list(range(10)):
            table_f.T[features[indices][j]][i]= importances[indices][j]
            #print (features[indices][j])
            #print (importances[indices][j])
        
​
#DROP ALL NAN ROWS
table_f = table_f.dropna(how='all')
​
for i in table_f.T.columns:
    table_f.T[i]['Mean'] = np.nanmean(table_f.T[i].values.tolist())
    table_f.T[i]['Stdev'] = np.nanstd(table_f.T[i].values.tolist())
    table_f.T[i]['Stdev/Mean %']= float(table_f.T[i]['Stdev'])/table_f.T[i]['Mean']*100











In [ ]:



























​











In [16]:



























table_var = pd.DataFrame( index = table.columns, columns =[list(['St.Dev', 'Stdev/Mean %'])])
#STUDY OF VARIANCE
​
for i in table.columns:
    table_var.T[i]['St.Dev']= statistics.stdev(table[i].values)
    table_var.T[i]['Stdev/Mean %']= table_var.T[i]['St.Dev']/statistics.mean(table[i].values)











In [ ]:



























​











In [17]:








writer = pd.ExcelWriter('Leadership_Features_Analysis.xlsx')
table_f.to_excel(writer, 'Feature Analysis')
table_var.to_excel(writer, 'Robustness')
writer.save()




















writer = pd.ExcelWriter('Leadership_Features_Analysis.xlsx')
table_f.to_excel(writer, 'Feature Analysis')
table_var.to_excel(writer, 'Robustness')
writer.save()
